{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMMCmMDHJGWaq4e7rsaRosM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anuragpandey2005/freelance-scrapper/blob/main/freelance_scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import logging\n",
        "logging.basicConfig(filename='scraper.log', level=logging.ERROR)"
      ],
      "metadata": {
        "id": "ik6gBESFGIx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Step 1: Environment Setup"
      ],
      "metadata": {
        "id": "_5igGVXl-xFV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODHczMnM-rsf"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n",
        "!pip install selenium webdriver-manager"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Step 2: Choose 3 Platforms\n",
        "\n",
        "We will use:\n",
        "\n",
        "* RemoteOK\n",
        "\n",
        "* PeoplePerHour\n",
        "\n",
        "* Wellfound (AngelList)\n",
        "\n"
      ],
      "metadata": {
        "id": "EYsPp1eg--rP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Step 3: Write the Scraper for Each Site\n",
        "\n",
        "üîπ remoteok.com"
      ],
      "metadata": {
        "id": "QbQJANlQ_TGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_remoteok():\n",
        "    url = \"https://remoteok.com/api\"\n",
        "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    data = response.json()[1:]  # First item is metadata\n",
        "\n",
        "    jobs = []\n",
        "    for job in data:\n",
        "        jobs.append({\n",
        "            \"Job Title\": job.get(\"position\"),\n",
        "            \"Job Description\": job.get(\"description\"),\n",
        "            \"Category/Tags\": \", \".join(job.get(\"tags\", [])),\n",
        "            \"Budget/Rate\": job.get(\"salary\"),\n",
        "            \"Client Location\": job.get(\"location\"),\n",
        "            \"Posting Date\": job.get(\"date\"),\n",
        "            \"Job URL\": f\"https://remoteok.com{job.get('url')}\"\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(jobs)\n"
      ],
      "metadata": {
        "id": "9sFNDwnK-7kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üîπ peopleperhour.com (uses static HTML scraping)\n"
      ],
      "metadata": {
        "id": "YM9VQsU7_lT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_peopleperhour():\n",
        "    url = \"https://www.peopleperhour.com/freelance-jobs\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    jobs = []\n",
        "    for job_card in soup.select(\".job-search-result\"):\n",
        "        jobs.append({\n",
        "            \"Job Title\": job_card.select_one(\".job-title\").text.strip() if job_card.select_one(\".job-title\") else None,\n",
        "            \"Job Description\": job_card.select_one(\".job-description\").text.strip() if job_card.select_one(\".job-description\") else None,\n",
        "            \"Category/Tags\": job_card.select_one(\".breadcrumb\").text.strip().replace(\"\\n\", \", \") if job_card.select_one(\".breadcrumb\") else \"N/A\",\n",
        "            \"Budget/Rate\": job_card.select_one(\".budget\").text.strip() if job_card.select_one(\".budget\") else None,\n",
        "            # PeoplePerHour doesn‚Äôt show client location without login\n",
        "            \"Client Location\": \"\",  # Field disabled due to login requirement\n",
        "            \"Posting Date\": job_card.select_one(\".job-footer > span\").text.strip() if job_card.select_one(\".job-footer > span\") else \"N/A\",\n",
        "            \"Job URL\": \"https://www.peopleperhour.com\" + job_card.a[\"href\"]\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(jobs)"
      ],
      "metadata": {
        "id": "7lWdurjb_hah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ wellfound.com (static scraping example ‚Äî very limited due to JavaScript use)"
      ],
      "metadata": {
        "id": "afXMc9VK_wZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "def scrape_wellfound():\n",
        "    service = Service(ChromeDriverManager().install())\n",
        "    driver = webdriver.Chrome(service=service)\n",
        "    driver.get(\"https://wellfound.com/jobs\")\n",
        "\n",
        "    jobs = []\n",
        "    # Wait for JavaScript to load (adjust time if needed)\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Extract job titles from the page\n",
        "    job_cards = driver.find_elements(By.CSS_SELECTOR, \".JobCard__Title\") ## Wellfound uses dynamic classes; inspect the page to update selectors if broken\n",
        "    for job in job_cards:\n",
        "        jobs.append({\n",
        "            \"Job Title\": job.find_element(By.CSS_SELECTOR, \".job-title\").text,\n",
        "            \"Job Description\": job.find_element(By.CSS_SELECTOR, \".description\").text,\n",
        "            \"Category/Tags\": \"Tech, Startup\",\n",
        "            \"Budget/Rate\": \"Varies\",\n",
        "            \"Client Location\": \"Global\",\n",
        "            \"Posting Date\": \"NA\",\n",
        "            \"Job URL\": job.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
        "        })\n",
        "\n",
        "    driver.quit()\n",
        "    return pd.DataFrame(jobs)\n",
        "# Wellfound uses React, so we need Selenium to render JavaScript\n",
        "# Warning: CSS classes change frequently! Re-inspect if this breaks.\n",
        "options = Options()\n",
        "options.add_argument('--headless')  # Run Chrome in background"
      ],
      "metadata": {
        "id": "Tz8_3PyF_qdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " * Exception Handling"
      ],
      "metadata": {
        "id": "hJotWl60J9My"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_remoteok():\n",
        "    try:\n",
        "        url = \"https://remoteok.com/api\"\n",
        "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)\n",
        "        response.raise_for_status()  # Check for HTTP errors\n",
        "        data = response.json()[1:]\n",
        "        # ... rest of your code ...\n",
        "    except Exception as e:\n",
        "        logging.error(f\"RemoteOK failed: {e}\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame"
      ],
      "metadata": {
        "id": "bqvmePk6ARhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# STEP 4: Combine data and save results"
      ],
      "metadata": {
        "id": "6CQZhgjw_0dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# STEP 4: Combine data and save results\n",
        "# ================================================\n",
        "def main():\n",
        "    try:\n",
        "        # Scrape all platforms\n",
        "        print(\"üü° Scraping RemoteOK...\")\n",
        "        df_remoteok = scrape_remoteok()\n",
        "\n",
        "        print(\"üü° Scraping PeoplePerHour...\")\n",
        "        df_peopleperhour = scrape_peopleperhour()\n",
        "\n",
        "        print(\"üü° Scraping Wellfound (this takes 10 seconds)...\")\n",
        "        df_wellfound = scrape_wellfound()\n",
        "\n",
        "        # Combine data\n",
        "        all_jobs = pd.concat(\n",
        "            [df_remoteok, df_peopleperhour, df_wellfound],\n",
        "            ignore_index=True\n",
        "        )\n",
        "\n",
        "        # Save with today's date\n",
        "        from datetime import datetime\n",
        "        today = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "        filename = f\"freelance_jobs_{today}.csv\"\n",
        "        all_jobs.to_csv(filename, index=False)\n",
        "\n",
        "        print(f\"‚úÖ Success! Saved {len(all_jobs)} jobs to {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Critical error: {e}\")\n",
        "        logging.error(f\"Main function failed: {e}\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "tSNpuOFZMo6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWGRlM3SMp4W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}